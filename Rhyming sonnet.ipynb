{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nltk\n",
    "import HMM as HMM\n",
    "import random\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    }
   ],
   "source": [
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct a dictionary mapping from word -> [# syllables], [# syllables when at the end of the word]\n",
    "syl_data = np.loadtxt('./data/Syllable_dictionary.txt', dtype='str', delimiter='\\n')\n",
    "syl_dict = {}\n",
    "for line in syl_data:\n",
    "    syl_list = line.split()\n",
    "    word = syl_list[0]\n",
    "    syl_dict[word] = [[],[]]\n",
    "    for i in range(1, len(syl_list)):\n",
    "        if syl_list[i].startswith('E'):\n",
    "            syl_dict[word][1].append(int(syl_list[i].lstrip('E')))\n",
    "        else:\n",
    "            syl_dict[word][0].append(int(syl_list[i]))\n",
    "\n",
    "sonnet_data = np.loadtxt('./data/shakespeare.txt', dtype='str', delimiter='\\n')\n",
    "\n",
    "# Construct a sequence of tokens from sonnets.\n",
    "sonnets = []\n",
    "sonnet_lines = []\n",
    "for line in sonnet_data:\n",
    "    if line.lstrip().isdigit():\n",
    "        sonnets.append([])\n",
    "        sonnet_lines.append([])\n",
    "    else:\n",
    "        tokens = word_tokenize(line)\n",
    "        sonnet_lines[-1].append([])\n",
    "        for i, token in enumerate(tokens):\n",
    "            if (not token.lower() in syl_dict) and (token.lstrip(\"'\").lower() in syl_dict):\n",
    "                t = token.lstrip(\"'\").lower()\n",
    "                sonnets[-1].append(t)\n",
    "                sonnet_lines[-1][-1].append(t)\n",
    "            elif (not token.lower() in syl_dict) and (token.lower() + \"'\" in syl_dict):\n",
    "                t = token.lower() + \"'\"\n",
    "                sonnets[-1].append(t)\n",
    "                sonnet_lines[-1][-1].append(t)\n",
    "            elif i != len(tokens) - 1 and (tokens[i+1] == \"'s\" or tokens[i+1] == \"'ll\"):\n",
    "                t = token.lower() + tokens[i+1]\n",
    "                sonnets[-1].append(t)\n",
    "                sonnet_lines[-1][-1].append(t)\n",
    "            elif i != len(tokens) - 1 and tokens[i+1] == \"is\" and tokens[i].lower() == \"'t\":\n",
    "                sonnets[-1].append(\"'tis\")\n",
    "                sonnet_lines[-1][-1].append(\"'tis\")\n",
    "            elif token in [\"'s\", \"'\", \"(\", \")\", \"'ll\"]:\n",
    "                continue\n",
    "            elif i != 0 and tokens[i-1].lower() == \"'t\" and tokens[i].lower() == \"is\":\n",
    "                continue\n",
    "            else:\n",
    "                t = token.lower()\n",
    "                sonnets[-1].append(t)\n",
    "                sonnet_lines[-1][-1].append(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "syl_dict['grossly'] = [[2], []]\n",
    "syl_dict['fickle'] = [[2], []]\n",
    "syl_dict['waning'] = [[2], []]\n",
    "syl_dict[\"show'st\"] = [[1], []]\n",
    "syl_dict['over'] = [[2], []]\n",
    "syl_dict['wrack'] = [[1], []]\n",
    "syl_dict['withering'] = [[2], []]\n",
    "syl_dict['goest'] = [[1], []]\n",
    "syl_dict['onwards'] = [[2], []]\n",
    "syl_dict['minion'] = [[2], []]\n",
    "syl_dict['detain'] = [[2], []]\n",
    "syl_dict['delayed'] = [[2], []]\n",
    "syl_dict['answered'] = [[2], []]\n",
    "syl_dict['quietus'] = [[3], []]\n",
    "for punct in ['.',',',':', '?', '!', ';']:\n",
    "    syl_dict[punct] = [[0],[]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_tokens = 0\n",
    "token_dict = {}\n",
    "num_dict = {}\n",
    "for j, sonnet in enumerate(sonnets):\n",
    "    for token in sonnet:\n",
    "        if not token in token_dict:\n",
    "            token_dict[token] = num_tokens\n",
    "            num_dict[num_tokens] = token\n",
    "            num_tokens += 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98\n",
      "15\n",
      "\n",
      "\n",
      "125\n",
      "12\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, sonnet in enumerate(sonnet_lines):\n",
    "    if (len(sonnet) != 14):\n",
    "        print(i)\n",
    "        print(len(sonnet))\n",
    "        print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_rhymes(t1, t2, rhymer):\n",
    "    if t1 in rhymer:\n",
    "        if t2 not in rhymer[t1]:\n",
    "            rhymer[t1].append(t2)\n",
    "    else:\n",
    "        rhymer[t1] = [t2]\n",
    "    if t2 in rhymer:\n",
    "        if t1 not in rhymer[t2]:\n",
    "            rhymer[t2].append(t1)\n",
    "    else: \n",
    "        rhymer[t2] = [t1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Form a rhyming dictionary, mapping each word to its rhymes.\n",
    "rhyming_dict = {}\n",
    "for sonnet in sonnet_lines:\n",
    "    if (len(sonnet) != 14):\n",
    "        continue\n",
    "    \n",
    "    last_tokens = []\n",
    "    for line in sonnet:\n",
    "        for i in range(len(line) - 1, -1, -1):\n",
    "            last_token = line[i]\n",
    "            if not last_token in ['.',',',':', '?', '!', ';']:\n",
    "                break\n",
    "        last_tokens.append(last_token)\n",
    "    \n",
    "    add_rhymes(last_tokens[0], last_tokens[2], rhyming_dict)\n",
    "    add_rhymes(last_tokens[1], last_tokens[3], rhyming_dict)\n",
    "    add_rhymes(last_tokens[4], last_tokens[6], rhyming_dict)\n",
    "    add_rhymes(last_tokens[5], last_tokens[7], rhyming_dict)\n",
    "    add_rhymes(last_tokens[8], last_tokens[10], rhyming_dict)\n",
    "    add_rhymes(last_tokens[9], last_tokens[11], rhyming_dict)\n",
    "    add_rhymes(last_tokens[12], last_tokens[13], rhyming_dict)\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return a token with the first alphanumeric character capitalized.\n",
    "def capitalize(token):\n",
    "    for i, c in enumerate(token):\n",
    "        if c.isalnum():\n",
    "            break\n",
    "    return token[0:i] + c.upper() + token[i+1:(len(token))]           \n",
    "\n",
    "# Turns the sonnet lines into a sonnet.\n",
    "def process_lines(sonnet_lines, punct):\n",
    "    for line in sonnet_lines:\n",
    "        line.reverse()\n",
    "    \n",
    "    processed_lines = [[] for i in range(len(sonnet_lines))]\n",
    "    for i, line in enumerate(sonnet_lines):\n",
    "        first_word_idx = i-1 if line[0] in punct else i\n",
    "        if first_word_idx != -1:\n",
    "            processed_lines[first_word_idx].append(line[0])\n",
    "        for j in range(1, len(line)):\n",
    "            processed_lines[i].append(line[j])\n",
    "    \n",
    "    for line in processed_lines:\n",
    "        line[0] = capitalize(line[0])\n",
    "        for i, token in enumerate(line):\n",
    "            if token in ['.', '!', '?'] and i != len(line) - 1:\n",
    "                line[i+1] = capitalize(line[i+1])\n",
    "            elif token in ['i', \"i'll\"]:\n",
    "                line[i] = capitalize(line[i])\n",
    "    \n",
    "    if processed_lines[-1][-1] != '.':\n",
    "        processed_lines[-1].append('.')\n",
    "    \n",
    "    joined_lines = [' '.join(tokens) for tokens in processed_lines]\n",
    "    return '\\n'.join(joined_lines)\n",
    "\n",
    "def generate_states(hmm, seq_len, word_num):\n",
    "    emission_probs = [out[word_num] for out in hmm.O]\n",
    "    sum_probs = sum(emission_probs)\n",
    "    emission_probs = [prob/float(sum_probs) for prob in emission_probs]\n",
    "    \n",
    "    rand = random.random()\n",
    "    sum_probs = 0\n",
    "    state = hmm.L - 1\n",
    "    for i, prob in enumerate(emission_probs):\n",
    "        sum_probs += prob\n",
    "        if rand < sum_probs:\n",
    "            state = i\n",
    "            break\n",
    "    states = []\n",
    "    \n",
    "    for i in range(0, seq_len):\n",
    "        rand = random.random()\n",
    "        sum_probs = 0\n",
    "        next_state = hmm.L - 1\n",
    "        for j, prob in enumerate(hmm.A[state]):\n",
    "            sum_probs += prob\n",
    "            if rand < sum_probs:\n",
    "                next_state = j\n",
    "                break\n",
    "        states.append(next_state)\n",
    "        state = next_state\n",
    "    return states\n",
    "\n",
    "def generate_emission(hmm, state):\n",
    "    rand = random.random()\n",
    "    sum_probs = 0\n",
    "    for i, prob in enumerate(hmm.O[state]):\n",
    "        sum_probs += prob\n",
    "        if rand < sum_probs:\n",
    "            return i\n",
    "    \n",
    "    return hmm.D - 1\n",
    "\n",
    "def generate_rhyming_sonnet(hmm, syl_dict, num_dict, token_dict, rhyming_dict):\n",
    "    '''\n",
    "    Input:\n",
    "        hmm: HMM\n",
    "        syl_dict: Maps token -> # syllables\n",
    "        num_dict: Maps token -> token #\n",
    "        token_dict: Maps token # -> token\n",
    "        rhyming_dict: Maps word -> rhyming words\n",
    "    '''\n",
    "    sonnet_lines = [[] for i in range(14)]\n",
    "    rhyming_list = list(rhyming_dict.keys())\n",
    "    words_to_rhyme = []\n",
    "    rhyming_words = []\n",
    "    for pair in [(0,2), (1,3), (4, 6), (5, 7), (8, 10), (9, 11), (12, 13)]:\n",
    "        word = random.choice(rhyming_list)\n",
    "        rhyming_word = random.choice(rhyming_dict[word])\n",
    "        sonnet_lines[pair[0]].append(word)\n",
    "        sonnet_lines[pair[1]].append(rhyming_word)  \n",
    "            \n",
    "    punctuation = ['.',',',':', '?', '!', ';']\n",
    "        \n",
    "    prev_token_is_punct = False\n",
    "    for i, line in enumerate(sonnet_lines):\n",
    "        states = generate_states(hmm, 20, token_dict[line[0]])\n",
    "        state = 0\n",
    "\n",
    "        # List of possible number of syllables in the line so far\n",
    "        possible_syls = syl_dict[line[0]][0]\n",
    "        while True:\n",
    "            token_num = generate_emission(hmm, states[state])\n",
    "            token = num_dict[token_num]\n",
    "            token_syls = syl_dict[token]\n",
    "            next_possible_syls = []\n",
    "            for num_syls in possible_syls:\n",
    "                for syls in token_syls[0] + token_syls[1]:\n",
    "                    next_possible_syls.append(syls + num_syls)\n",
    "\n",
    "            # Generate another token and try again with the same state. \n",
    "            if min(next_possible_syls) > 10:\n",
    "                continue\n",
    "            \n",
    "            cur_token_is_punct = token in punctuation\n",
    "            if prev_token_is_punct and cur_token_is_punct:\n",
    "                continue\n",
    "            \n",
    "            prev_token_is_punct = cur_token_is_punct\n",
    "                  \n",
    "            # Line is complete, go to next line.\n",
    "            if 10 in next_possible_syls:\n",
    "                line.append(token)\n",
    "                break           \n",
    "            \n",
    "            # In this case, the line is not complete. Add the token to the sonnet,\n",
    "            # update possible_syls, and increment state.\n",
    "            line.append(token)\n",
    "            state += 1\n",
    "            possible_syls = [a + b for a in possible_syls for b in token_syls[0]]\n",
    "    return process_lines(sonnet_lines, punctuation)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 10\n",
      "Iteration: 20\n",
      "Iteration: 30\n"
     ]
    }
   ],
   "source": [
    "number_sonnets = [[token_dict[token] for token in sonnet] for sonnet in sonnets]\n",
    "for sonnet in number_sonnets:\n",
    "    sonnet.reverse()\n",
    "hmm = HMM.unsupervised_HMM(number_sonnets, 15, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gives my eye her , I in I the crowned\n",
      "Winter and those praise , then his roses , where\n",
      "Thy worth in am , they the heavenly confound\n",
      "Self I prognosticate . Then alters there\n",
      "Than for love-suit gift : when will deserv'st joy\n",
      "Sight of day with true sometime , so enlarged\n",
      "Being so scanted of less , shadow's annoy\n",
      "Injuries distempered lies being my charged\n",
      "Something of so , 'tis but never distilled\n",
      "I , for you , as if nature frown are loved\n",
      "Of fickle own should . My dear love self-killed\n",
      "Supposed rearward , and show greet me proved\n",
      "Own state , form with thy fashion is commend\n",
      "Lesser , and their night the desire bad mend .\n"
     ]
    }
   ],
   "source": [
    "print(generate_rhyming_sonnet(hmm, syl_dict, num_dict, token_dict, rhyming_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 2), (3, 5)]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
