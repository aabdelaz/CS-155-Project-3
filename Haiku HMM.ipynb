{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import HMM\n",
    "import sonnet_utils as utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sonnets, syl_dict, num_dict, token_dict = utils.process_data('./data/Syllable_dictionary.txt', './data/shakespeare.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return a token with the first alphanumeric character capitalized.\n",
    "def capitalize(token):\n",
    "    for i, c in enumerate(token):\n",
    "        if c.isalnum():\n",
    "            break\n",
    "    return token[0:i] + c.upper() + token[i+1:(len(token))]           \n",
    "\n",
    "# Turns the sonnet lines into a sonnet.\n",
    "def process_lines(sonnet_lines, punct):\n",
    "    processed_lines = [[] for i in range(len(sonnet_lines))]\n",
    "    # Moves punctuation from beginning of line to end of previous line.\n",
    "    for i, line in enumerate(sonnet_lines):\n",
    "        first_word_idx = i-1 if line[0] in punct else i\n",
    "        if first_word_idx != -1:\n",
    "            processed_lines[first_word_idx].append(line[0])\n",
    "        for j in range(1, len(line)):\n",
    "            processed_lines[i].append(line[j])\n",
    "    \n",
    "    processed_lines[0][0] = capitalize(processed_lines[0][0])\n",
    "    for j, line in enumerate(processed_lines):\n",
    "        for i, token in enumerate(line):\n",
    "            if token in ['.', '!', '?']:\n",
    "                if i != len(line) - 1:\n",
    "                    line[i+1] = capitalize(line[i+1])\n",
    "                else:\n",
    "                    processed_lines[j+1][0] = capitalize(processed_lines[j+1][0]) \n",
    "            elif token in ['i', \"i'll\"]:\n",
    "                line[i] = capitalize(line[i])\n",
    "    \n",
    "    if processed_lines[-1][-1] != '.':\n",
    "        processed_lines[-1].append('.')\n",
    "    \n",
    "    joined_lines = [' '.join(tokens) for tokens in processed_lines]\n",
    "    return '\\n'.join(joined_lines)\n",
    "\n",
    "import random\n",
    "\n",
    "def generate_states(hmm, seq_len):\n",
    "    states = [random.choice(range(hmm.L))]\n",
    "    state = states[0]\n",
    "    for i in range(1, seq_len):\n",
    "        rand = random.random()\n",
    "        sum_probs = 0\n",
    "        next_state = hmm.L - 1\n",
    "        for j, prob in enumerate(hmm.A[state]):\n",
    "            sum_probs += prob\n",
    "            if rand < sum_probs:\n",
    "                next_state = j\n",
    "                break\n",
    "        states.append(next_state)\n",
    "        state = next_state\n",
    "    return states\n",
    "\n",
    "def generate_emission(hmm, state):\n",
    "    rand = random.random()\n",
    "    sum_probs = 0\n",
    "    for i, prob in enumerate(hmm.O[state]):\n",
    "        sum_probs += prob\n",
    "        if rand < sum_probs:\n",
    "            return i\n",
    "    \n",
    "    return hmm.D - 1\n",
    "\n",
    "def generate_haiku(hmm, syl_dict, num_dict):\n",
    "    punctuation = ['.',',',':', '?', '!', ';']\n",
    "    states = generate_states(hmm, 50)\n",
    "    lines = [[] for i in range(3)]\n",
    "    line_lens = [5, 7, 5]\n",
    "    state = 0\n",
    "    prev_token_is_punct = False\n",
    "    for i in range(3):\n",
    "        line = lines[i]\n",
    "        # List of possible number of syllables in the line so far\n",
    "        possible_syls = [0]\n",
    "        while True:\n",
    "            token_num = generate_emission(hmm, states[state])\n",
    "            token = num_dict[token_num]\n",
    "            token_syls = syl_dict[token]\n",
    "            next_possible_syls = []\n",
    "            for num_syls in possible_syls:\n",
    "                for syls in token_syls[0] + token_syls[1]:\n",
    "                    next_possible_syls.append(syls + num_syls)\n",
    "\n",
    "            # Generate another token and try again with the same state.\n",
    "            # Allow the line if it is only one syllable off.\n",
    "            if min(next_possible_syls) > line_lens[i] and max(possible_syls) < line_lens[i] - 1:\n",
    "                continue\n",
    "                        \n",
    "            cur_token_is_punct = token in punctuation\n",
    "            if prev_token_is_punct and cur_token_is_punct:\n",
    "                continue\n",
    "            \n",
    "            prev_token_is_punct = cur_token_is_punct\n",
    "            \n",
    "            if line_lens[i] in next_possible_syls or min(next_possible_syls) > line_lens[i]:\n",
    "                line.append(token)\n",
    "                state += 1\n",
    "                break         \n",
    "            \n",
    "            # In this case, the line is not complete. Add the token to the sonnet,\n",
    "            # update possible_syls, and increment state.\n",
    "            line.append(token)\n",
    "            state += 1\n",
    "            possible_syls = [a + b for a in possible_syls for b in token_syls[0]]\n",
    "    return process_lines(lines, punctuation)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 10\n",
      "Iteration: 20\n",
      "Iteration: 30\n",
      "Iteration: 40\n",
      "Iteration: 50\n"
     ]
    }
   ],
   "source": [
    "number_sonnets = [[token_dict[token] for token in sonnet] for sonnet in sonnets]\n",
    "hmm = HMM.unsupervised_HMM(number_sonnets, 50, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "But best ink contents\n",
      "me , when maiden time . Be thou\n",
      "harder I thy name .\n",
      "\n",
      "\n",
      "Ill to her , or for\n",
      "my am shadow the weed of\n",
      "these , and falls , and all .\n",
      "\n",
      "\n",
      "Give boat , and true of\n",
      "sepulchres , like in the willing\n",
      "provide foul and carve .\n",
      "\n",
      "\n",
      "World till no woe with\n",
      "love's poet thy beauty rage ,\n",
      "before being take .\n",
      "\n",
      "\n",
      "Foul no gone were this\n",
      "purpose , and in fist upon\n",
      "the cheer , nor horse to .\n",
      "\n",
      "\n",
      "That in my dream , and\n",
      "to thy golden from my abuse .\n",
      "Spurring do thou hadst .\n",
      "\n",
      "\n",
      "But eyes she faster\n",
      "for let a judgment on the\n",
      "best on one , summer's .\n",
      "\n",
      "\n",
      "Successive thou : nor\n",
      "for my lays . And I knows day :\n",
      "such that I saw from .\n",
      "\n",
      "\n",
      "Both ; and tender thou\n",
      "boundless aright , all own think\n",
      "to that ! For mind find .\n",
      "\n",
      "\n",
      "When up-locked cast\n",
      "I thy loving canker and\n",
      "good plagues for but waste .\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(generate_haiku(hmm,syl_dict, num_dict))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
